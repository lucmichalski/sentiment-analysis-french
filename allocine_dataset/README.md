# Allociné Dataset

> A large-scale sentiment analysis dataset in French language

## Scraping

All scraping functions are defined in [allocine_scraper.py][allocine_scraper.py].
With these, extracting reviews from the whole [Allociné.fr](http://www.allocine.fr) website can be done with only a few lines of code (here limiting to 30 reviews per movie):

```python
ROOT_URL = "http://www.allocine.fr"
MAX_REVIEWS_PER_MOVIE = 30

urls = get_film_urls(ROOT_URL)
dic = get_film_reviews(ROOT_URL, batch_urls, MAX_REVIEWS_PER_MOVIE)
```

Getting all the data at once can become awfully time-consuming.
The [scrape_allocine.ipynb][scrape_allocine.ipynb] notebook points out my strategy, which is to process batches of URLs instead of the full list.
I also used this notebook to generate intermediate `.pickle` files that compile all the extracted data in a [pandas](https://pandas.pydata.org/pandas-docs/stable/index.html) `DataFrame`.

## Exploring data

The following results and images were generated by the [create_dataset.ipynb][create_dataset.ipynb] notebook.

### Rating counts

User ratings range from 0.5 to 5 with a step of 0.5 between each.
As we can see, on the following graph, there are more positive reviews than negative, with a significant peak at 4.

<p align="center">
    <img src="/allocine_dataset/img/rating_counts.png" width="650" >
</p>

In order to build a binary sentiment analysis dataset, we need to assign to each review its corresponding polarity.
In the notebook, all reviews with a rating <= 2 are labeled as `negative`, while those with a rating >= 4 are `positive`.
In-between reviews are considered `neutral`.
With these empirical thresholding values, we obtain the following distribution :

<p align="center">
    <img src="/allocine_dataset/img/polarity_frequency.png" width="650" >
</p>

### Reviews length

The following graph depicts the length (number of characters) distribution of reviews.
We can see that most reviews are condensed before 5000, and that there is a large tail of long reviews.

<p align="center">
    <img src="/allocine_dataset/img/reviews_length.png" width="650" >
</p>

In the notebook, only the reviews with less than 2000 characters are kept.
This process actually removes 6% of the data, which leads to the following distribution :

<p align="center">
    <img src="/allocine_dataset/img/short_reviews_length.png" width="650" >
</p>

## Building the dataset

In order to build the dataset, we then randomly sample 100k `negative` and 100k `positive` reviews from the initial data, and split them into three subsets : *train* (80% of data), *validation* (10%) and *test* (10%).
We make sure that these subsets contain disjoint sets of movies, while being as balanced as possible.
The final results of the [create_dataset.ipynb][create_dataset.ipynb] notebook are as follow:

<p align="center">
    <img src="/allocine_dataset/img/splits_polarity.png" width="650" >
</p>

The resulting dataset is then exported as [`.jsonl`](http://jsonlines.org/) files, as well as a [`.pickle`](https://docs.python.org/3/library/pickle.html) file, and archived into [data.tar.bz2][data.tar.bz2].

## Author

Théophile Blard – :email: theophile.blard@gmail.com

If you use this work (code or dataset), please cite as:

> Théophile Blard, French sentiment analysis with BERT, (2020), GitHub repository, <https://github.com/TheophileBlard/french-sentiment-analysis-with-bert>

<!-- Markdown link & img dfn's -->
[allocine_scraper.py]: https://github.com/TheophileBlard/french-sentiment-analysis-with-bert/blob/master/allocine_dataset/allocine_scraper.py
[scrape_allocine.ipynb]: https://github.com/TheophileBlard/french-sentiment-analysis-with-bert/blob/master/allocine_dataset/scrape_allocine.ipynb
[create_dataset.ipynb]: https://github.com/TheophileBlard/french-sentiment-analysis-with-bert/blob/master/allocine_dataset/create_dataset.ipynb
[data.tar.bz2]: https://github.com/TheophileBlard/french-sentiment-analysis-with-bert/blob/master/allocine_dataset/data.tar.bz2
